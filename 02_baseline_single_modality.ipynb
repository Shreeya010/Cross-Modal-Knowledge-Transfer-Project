{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 3: Modeling Approaches\n"
      ],
      "metadata": {
        "id": "vChI8bnzn1Fd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from pathlib import Path\n",
        "\n",
        "# Load preprocessed data\n",
        "RESULTS_DIR = Path(\"/content/results\")\n",
        "df = pd.read_csv(RESULTS_DIR / \"/content/results/preprocessed_trials.csv\")\n",
        "print(f\"✅ Loaded preprocessed_trials.csv (Shape: {df.shape})\")\n",
        "\n",
        "# Define modality feature groups (adjust prefixes based on extraction)\n",
        "modalities = {\n",
        "    'EEG': [col for col in df.columns if col.startswith('EEG_') or col.startswith('PCA_')],  # Teacher\n",
        "    'Eye': [col for col in df.columns if col.startswith('EYE_') or col.startswith('IVT_')],  # Combined Eye-tracking\n",
        "    'GSR': [col for col in df.columns if col.startswith('GSR_')],\n",
        "    'Facial': [col for col in df.columns if col.startswith('TIVA_')]  # Facial expressions\n",
        "}\n",
        "\n",
        "y = df['Target_encoded']  # Binary target\n",
        "\n",
        "# Function to evaluate model\n",
        "def evaluate_model(y_true, y_pred, y_prob=None):\n",
        "    metrics = {\n",
        "        'F1-score': f1_score(y_true, y_pred),\n",
        "        'Accuracy': accuracy_score(y_true, y_pred)\n",
        "    }\n",
        "    if y_prob is not None:\n",
        "        metrics['ROC-AUC'] = roc_auc_score(y_true, y_prob)\n",
        "    return metrics\n",
        "\n",
        "# -------------------------------\n",
        "# 3.1 Baseline (Single-Modality Models)\n",
        "# -------------------------------\n",
        "baseline_results = {}\n",
        "for modality, features in modalities.items():\n",
        "    if not features:\n",
        "        print(f\"⚠️ No features for {modality}\")\n",
        "        continue\n",
        "    X = df[features].select_dtypes(include=[np.number]).fillna(0)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)  # Stratify for imbalance\n",
        "\n",
        "    model = xgb.XGBClassifier(random_state=42, scale_pos_weight=1 if y_train.mean() > 0.5 else 1/y_train.mean())  # Handle imbalance\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_prob = model.predict_proba(X_test)[:, 1]\n",
        "    metrics = evaluate_model(y_test, y_pred, y_prob)\n",
        "    baseline_results[modality] = metrics\n",
        "    print(f\"✅ Baseline {modality}: {metrics}\")\n",
        "\n",
        "    # Save model\n",
        "    model.save_model(RESULTS_DIR / f\"{modality.lower()}_baseline.json\")\n",
        "\n",
        "# Save baseline results\n",
        "pd.DataFrame(baseline_results).T.to_csv(RESULTS_DIR / \"/content/results/baseline_results.csv\")\n",
        "print(\"✅ Baseline results saved\")\n",
        "\n",
        "# Load teacher model (EEG baseline) and generate soft labels\n",
        "if modalities['EEG']:\n",
        "    teacher_model = xgb.XGBClassifier()\n",
        "    teacher_model.load_model(RESULTS_DIR / \"/content/results/eeg_baseline.json\")\n",
        "    X_eeg = df[modalities['EEG']].select_dtypes(include=[np.number]).fillna(0)\n",
        "    teacher_probs = teacher_model.predict_proba(X_eeg)[:, 1]\n",
        "else:\n",
        "    print(\"❌ No EEG features to load teacher model\")\n",
        "    teacher_probs = None\n",
        "\n",
        "# -------------------------------\n",
        "# 3.2 Knowledge Transfer (Knowledge Distillation)\n",
        "# -------------------------------\n",
        "def create_student_nn(input_dim):\n",
        "    return models.Sequential([\n",
        "        layers.Input(shape=(input_dim,)),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(32, activation='relu'),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "def distillation_loss(y_true, y_pred, teacher_probs, temperature=2.0, alpha=0.5):\n",
        "    y_pred = tf.squeeze(y_pred)\n",
        "    soft_pred = tf.math.sigmoid(y_pred / temperature)\n",
        "    soft_teacher = teacher_probs / temperature\n",
        "    hard_loss = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
        "    soft_loss = tf.keras.losses.kullback_leibler_divergence(soft_teacher, soft_pred)\n",
        "    return alpha * soft_loss + (1 - alpha) * hard_loss\n",
        "\n",
        "distillation_results = {}\n",
        "for modality in ['Eye', 'GSR', 'Facial']:\n",
        "    features = modalities[modality]\n",
        "    if not features or teacher_probs is None:\n",
        "        print(f\"⚠️ No features or teacher for {modality}\")\n",
        "        continue\n",
        "    X = df[features].select_dtypes(include=[np.number]).fillna(0)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "    train_indices = X_train.index\n",
        "    teacher_probs_train = teacher_probs[train_indices]\n",
        "\n",
        "    student_model = create_student_nn(X_train.shape[1])\n",
        "    student_model.compile(optimizer='adam', loss=lambda y_true, y_pred: distillation_loss(y_true, y_pred, teacher_probs_train))\n",
        "    student_model.fit(X_train, y_train, epochs=20, batch_size=32, verbose=0)\n",
        "\n",
        "    y_pred = (student_model.predict(X_test) > 0.5).astype(int).flatten()\n",
        "    y_prob = student_model.predict(X_test).flatten()\n",
        "    metrics = evaluate_model(y_test, y_pred, y_prob)\n",
        "    distillation_results[modality] = metrics\n",
        "    print(f\"✅ Distillation {modality}: {metrics}\")\n",
        "\n",
        "    student_model.save(RESULTS_DIR / f\"{modality.lower()}_student.h5\")\n",
        "\n",
        "pd.DataFrame(distillation_results).T.to_csv(RESULTS_DIR / \"/content/results/distillation_results.csv\")\n",
        "print(\"✅ Distillation results saved\")\n",
        "\n",
        "# -------------------------------\n",
        "# 3.3 Domain Adaptation Approaches\n",
        "# -------------------------------\n",
        "# Shared function for feature extractor\n",
        "def create_feature_extractor(input_dim, embedding_dim=16):\n",
        "    return models.Sequential([\n",
        "        layers.Input(shape=(input_dim,)),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(32, activation='relu'),\n",
        "        layers.Dense(embedding_dim, activation='relu', name='embedding')\n",
        "    ])\n",
        "\n",
        "# 3.3.1 Adversarial Domain Adaptation (Fixed model definition)\n",
        "if modalities['EEG'] and modalities.get('Eye'):  # Example with Eye; extend for others\n",
        "    X_teacher = df[modalities['EEG']].select_dtypes(include=[np.number]).fillna(0)\n",
        "    X_student = df[modalities['Eye']].select_dtypes(include=[np.number]).fillna(0)\n",
        "    X_teacher_train, X_teacher_test, X_student_train, X_student_test, y_train, y_test = train_test_split(\n",
        "        X_teacher, X_student, y, test_size=0.2, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    embedding_dim = 16\n",
        "    feature_extractor_teacher = create_feature_extractor(X_teacher_train.shape[1], embedding_dim)\n",
        "    feature_extractor_student = create_feature_extractor(X_student_train.shape[1], embedding_dim)\n",
        "    label_predictor = models.Sequential([layers.Dense(embedding_dim, activation='relu'), layers.Dense(1, activation='sigmoid')])\n",
        "    domain_discriminator = models.Sequential([layers.Dense(embedding_dim, activation='relu'), layers.Dense(1, activation='sigmoid')])\n",
        "\n",
        "    @tf.custom_gradient\n",
        "    def gradient_reversal(x):\n",
        "        def grad(dy):\n",
        "            return -dy\n",
        "        return x, grad\n",
        "\n",
        "    class GradientReversalLayer(layers.Layer):\n",
        "        def call(self, x):\n",
        "            return gradient_reversal(x)\n",
        "\n",
        "    # Inputs\n",
        "    teacher_input = layers.Input(shape=(X_teacher_train.shape[1],))\n",
        "    student_input = layers.Input(shape=(X_student_train.shape[1],))\n",
        "    labels_input = layers.Input(shape=(1,))\n",
        "    domain_labels_input = layers.Input(shape=(1,))\n",
        "\n",
        "    # Embeddings\n",
        "    teacher_embedding = feature_extractor_teacher(teacher_input)\n",
        "    student_embedding = feature_extractor_student(student_input)\n",
        "\n",
        "    # Predictions\n",
        "    label_pred = label_predictor(student_embedding)\n",
        "    domain_pred_teacher = domain_discriminator(GradientReversalLayer()(teacher_embedding))\n",
        "    domain_pred_student = domain_discriminator(GradientReversalLayer()(student_embedding))\n",
        "\n",
        "    # Model\n",
        "    ada_model = models.Model(\n",
        "        inputs=[teacher_input, student_input, labels_input, domain_labels_input],\n",
        "        outputs=[label_pred, domain_pred_teacher, domain_pred_student]\n",
        "    )\n",
        "    ada_model.compile(\n",
        "        optimizer='adam',\n",
        "        loss=['binary_crossentropy', 'binary_crossentropy', 'binary_crossentropy'],\n",
        "        loss_weights=[1.0, 0.5, 0.5]\n",
        "    )\n",
        "\n",
        "    # Domain labels\n",
        "    domain_labels_teacher = np.zeros(len(X_teacher_train))\n",
        "    domain_labels_student = np.ones(len(X_student_train))\n",
        "\n",
        "    # Train\n",
        "    ada_model.fit(\n",
        "        [X_teacher_train, X_student_train, y_train, domain_labels_teacher],\n",
        "        [y_train, domain_labels_teacher, domain_labels_student],\n",
        "        epochs=20, batch_size=32, verbose=1\n",
        "    )\n",
        "\n",
        "    # Evaluate\n",
        "    student_embeddings_test = feature_extractor_student(X_student_test)\n",
        "    y_pred = (label_predictor(student_embeddings_test) > 0.5).numpy().astype(int).flatten()\n",
        "    y_prob = label_predictor(student_embeddings_test).numpy().flatten()\n",
        "    ada_metrics = evaluate_model(y_test, y_pred, y_prob)\n",
        "    print(f\"✅ Adversarial DA (Eye): {ada_metrics}\")\n",
        "\n",
        "    ada_model.save(RESULTS_DIR / \"ada_eye.h5\")\n",
        "    pd.DataFrame({'ADA_Eye': ada_metrics}).T.to_csv(RESULTS_DIR / \"ada_results.csv\")\n",
        "else:\n",
        "    print(\"❌ Insufficient features for Adversarial DA\")\n",
        "\n",
        "# 3.3.2 Contrastive Learning (Skipped due to missing features)\n",
        "print(\"❌ Contrastive Learning skipped due to missing student features\")\n",
        "\n",
        "print(\"✅ Step 3 Complete - Modeling done (with limitations)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzH2-9TxMHTL",
        "outputId": "9a4ee1c8-48a1-44a8-c556-0777c3d1bfe8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded preprocessed_trials.csv (Shape: (425096, 12))\n",
            "✅ Baseline EEG: {'F1-score': 0.5263064971751412, 'Accuracy': 0.6213126323218067, 'ROC-AUC': np.float64(0.7594613012613253)}\n",
            "⚠️ No features for Eye\n",
            "⚠️ No features for GSR\n",
            "⚠️ No features for Facial\n",
            "✅ Baseline results saved\n",
            "⚠️ No features or teacher for Eye\n",
            "⚠️ No features or teacher for GSR\n",
            "⚠️ No features or teacher for Facial\n",
            "✅ Distillation results saved\n",
            "❌ Insufficient features for Adversarial DA\n",
            "❌ Contrastive Learning skipped due to missing student features\n",
            "✅ Step 3 Complete - Modeling done (with limitations)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"✅ Checking columns: {df.columns.tolist()}\")\n",
        "print(f\"✅ EEG features found: {modalities['EEG']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxOAkbKDVxk1",
        "outputId": "5ed2507c-ba63-41e3-bd35-d218086fdb99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Checking columns: ['participant_id', 'Target_encoded', 'PCA_1', 'PCA_2', 'PCA_3', 'PCA_4', 'PCA_5', 'PCA_6', 'PCA_7', 'PCA_8', 'PCA_9', 'PCA_10']\n",
            "✅ EEG features found: ['PCA_1', 'PCA_2', 'PCA_3', 'PCA_4', 'PCA_5', 'PCA_6', 'PCA_7', 'PCA_8', 'PCA_9', 'PCA_10']\n"
          ]
        }
      ]
    }
  ]
}